{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bed1734",
   "metadata": {},
   "source": [
    "Module 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32e0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d123905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.1+cu118\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e7cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacf515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor() \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e92d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../dataset/train\"\n",
    "val_dir   = \"../dataset/val\"\n",
    "test_dir  = \"../dataset/test\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=basic_transform)\n",
    "val_dataset   = datasets.ImageFolder(val_dir, transform=basic_transform)\n",
    "test_dataset  = datasets.ImageFolder(test_dir, transform=basic_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a278f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 429\n",
      "First 10 classes: ['Audi_Audi_A1', 'Audi_Audi_A3_hatchback', 'Audi_Audi_A3_sedan', 'Audi_Audi_A4L', 'Audi_Audi_A4_estate', 'Audi_Audi_A5_convertible', 'Audi_Audi_A5_coupe', 'Audi_Audi_A5_hatchback', 'Audi_Audi_A6L', 'Audi_Audi_A7']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"First 10 classes:\", train_dataset.classes[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51edcf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([32, 3, 224, 224])\n",
      "Labels shape: torch.Size([32])\n",
      "First 10 labels: tensor([ 77, 307,  56,   5, 394, 357, 333,  26, 178,  40])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"First 10 labels:\", labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328db28",
   "metadata": {},
   "source": [
    "Module 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e710e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),              # slightly larger\n",
    "    transforms.RandomCrop(224),                  # position invariance\n",
    "    transforms.RandomHorizontalFlip(p=0.5),      # left-right symmetry\n",
    "    transforms.RandomRotation(degrees=7),        # small camera tilt\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7812fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9838a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(val_dir, transform=eval_transform)\n",
    "test_dataset  = datasets.ImageFolder(test_dir, transform=eval_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "267b26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create DataLoaders after changing transforms\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ccae71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b98d34",
   "metadata": {},
   "source": [
    "Module 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f657cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "backbone=resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f3f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(backbone.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8839eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = backbone.fc.in_features\n",
    "\n",
    "backbone.fc = nn.Identity()  # removes ImageNet head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e9daf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarClassifier(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        outputs = self.classifier(features)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3fac452",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CarClassifier(backbone, num_classes)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a351e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 429])\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # VERY IMPORTANT\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dummy_output = model(dummy_input)\n",
    "\n",
    "print(\"Output shape:\", dummy_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fdf96",
   "metadata": {},
   "source": [
    "Module 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3c0f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze ALL backbone parameters\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7effd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 883,117\n",
      "Frozen params:    23,508,032\n"
     ]
    }
   ],
   "source": [
    "def count_trainable_params(model):\n",
    "    trainable = 0\n",
    "    frozen = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable += param.numel()\n",
    "        else:\n",
    "            frozen += param.numel()\n",
    "    return trainable, frozen\n",
    "\n",
    "trainable, frozen = count_trainable_params(model)\n",
    "\n",
    "print(f\"Trainable params: {trainable:,}\")\n",
    "print(f\"Frozen params:    {frozen:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62a47b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CarClassifier(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=2048, out_features=429, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c722dd4",
   "metadata": {},
   "source": [
    "Module 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11829c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427a9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    model.classifier.parameters(),  # ONLY head parameters\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49ce0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: 6.519368648529053\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "print(\"Loss value:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb3065b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04158f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=True):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7ffd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\", leave=True):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "455c84cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:04<00:00,  5.13it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:26<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Train Loss: 5.6045, Train Acc: 0.0495 | Val Loss: 4.6191, Val Acc: 0.1424 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:03<00:00,  5.20it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:26<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] | Train Loss: 4.1033, Train Acc: 0.1977 | Val Loss: 3.9758, Val Acc: 0.2301 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:04<00:00,  5.15it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] | Train Loss: 3.4041, Train Acc: 0.2936 | Val Loss: 3.6969, Val Acc: 0.2637 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:04<00:00,  5.12it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] | Train Loss: 2.9844, Train Acc: 0.3628 | Val Loss: 3.4518, Val Acc: 0.3104 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:06<00:00,  4.96it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] | Train Loss: 2.7231, Train Acc: 0.4072 | Val Loss: 3.2877, Val Acc: 0.3390 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_PHASE1 = 5\n",
    "\n",
    "for epoch in range(EPOCHS_PHASE1):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS_PHASE1}] | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
    "        f\"LR: {current_lr:.6f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e80b3b",
   "metadata": {},
   "source": [
    "Phase 2 training (un-freezing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fddbce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze only the last ResNet block\n",
    "for param in model.backbone.layer4.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5ffa46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 15,847,853\n",
      "Frozen params:    8,543,296\n"
     ]
    }
   ],
   "source": [
    "trainable, frozen = count_trainable_params(model)\n",
    "\n",
    "print(f\"Trainable params: {trainable:,}\")\n",
    "print(f\"Frozen params:    {frozen:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c176682",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": model.backbone.layer4.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": 1e-3},\n",
    "    ],\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cde423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb338540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, val_loss, model):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_state = {\n",
    "                k: v.detach().cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "            return False  # do not stop\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c5408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.25it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:30<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 2.2714, Train Acc: 0.4786 | Val Loss: 2.5020, Val Acc: 0.4636 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:20<00:00,  4.11it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15] | Train Loss: 1.6805, Train Acc: 0.5863 | Val Loss: 2.1672, Val Acc: 0.5224 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:16<00:00,  4.33it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:32<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15] | Train Loss: 1.2848, Train Acc: 0.6726 | Val Loss: 1.9054, Val Acc: 0.5741 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.26it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:26<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15] | Train Loss: 0.9648, Train Acc: 0.7373 | Val Loss: 1.7821, Val Acc: 0.6014 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:16<00:00,  4.31it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:28<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15] | Train Loss: 0.7890, Train Acc: 0.7866 | Val Loss: 1.6816, Val Acc: 0.6196 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.25it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:28<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15] | Train Loss: 0.6778, Train Acc: 0.8072 | Val Loss: 1.6268, Val Acc: 0.6407 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:16<00:00,  4.31it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15] | Train Loss: 0.5733, Train Acc: 0.8390 | Val Loss: 1.5425, Val Acc: 0.6623 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:15<00:00,  4.36it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15] | Train Loss: 0.5065, Train Acc: 0.8552 | Val Loss: 1.5014, Val Acc: 0.6701 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:14<00:00,  4.42it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:26<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15] | Train Loss: 0.4539, Train Acc: 0.8680 | Val Loss: 1.5180, Val Acc: 0.6755 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:16<00:00,  4.29it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] | Train Loss: 0.4159, Train Acc: 0.8789 | Val Loss: 1.4570, Val Acc: 0.6941 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.28it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15] | Train Loss: 0.3769, Train Acc: 0.8916 | Val Loss: 1.4701, Val Acc: 0.7003 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.24it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:28<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15] | Train Loss: 0.3586, Train Acc: 0.8921 | Val Loss: 1.5451, Val Acc: 0.6945 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.23it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:27<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15] | Train Loss: 0.3401, Train Acc: 0.9011 | Val Loss: 1.5017, Val Acc: 0.6941 | LR(backbone): 0.000100, LR(head): 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 330/330 [01:17<00:00,  4.24it/s]\n",
      "Validation: 100%|██████████| 76/76 [00:28<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping triggered at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_PHASE2 = 15\n",
    "early_stopper = EarlyStopping(patience=4)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS_PHASE2):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    stop = early_stopper.step(val_loss, model)\n",
    "    if stop:\n",
    "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "        model.load_state_dict(early_stopper.best_state)\n",
    "        break\n",
    "\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    current_lr_head = optimizer.param_groups[1][\"lr\"]\n",
    "    current_lr_backbone = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS_PHASE2}] | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} | \"\n",
    "        f\"LR(backbone): {current_lr_backbone:.6f}, \"\n",
    "        f\"LR(head): {current_lr_head:.6f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716ba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x21591b1bcd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64ef5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_top1(model, loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d7996d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Top-1 Accuracy: 0.6982\n"
     ]
    }
   ],
   "source": [
    "test_top1 = evaluate_top1(model, test_loader, device)\n",
    "print(f\"Test Top-1 Accuracy: {test_top1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "340a1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_top5(model, loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, top5 = outputs.topk(5, dim=1)\n",
    "\n",
    "            correct += sum(\n",
    "                labels[i].item() in top5[i]\n",
    "                for i in range(labels.size(0))\n",
    "            )\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba03d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Top-5 Accuracy: 0.8798\n"
     ]
    }
   ],
   "source": [
    "test_top5 = evaluate_top5(model, test_loader, device)\n",
    "print(f\"Test Top-5 Accuracy: {test_top5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abc95ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {v: k for k, v in train_dataset.class_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66881442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_top5(model, image_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.unsqueeze(0).to(device)  # [1,3,224,224]\n",
    "        outputs = model(image_tensor)\n",
    "\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        top5_probs, top5_indices = probs.topk(5)\n",
    "\n",
    "        results = []\n",
    "        for i in range(5):\n",
    "            class_name = idx_to_class[top5_indices[0][i].item()]\n",
    "            confidence = top5_probs[0][i].item()\n",
    "            results.append((class_name, confidence))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38c08b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audi_Audi_A1: 98.65%\n",
      "Audi_Audi_A3_hatchback: 1.23%\n",
      "Chevy_Cruze_sedan: 0.03%\n",
      "Citroen_Quatre_hatchback: 0.02%\n",
      "Mitsubishi_ASX_abroad_version: 0.02%\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "img = Image.open(\"test_car.jpg\").convert(\"RGB\")\n",
    "\n",
    "img_tensor = eval_transform(img)\n",
    "\n",
    "preds = predict_top5(model, img_tensor, device)\n",
    "\n",
    "for name, conf in preds:\n",
    "    print(f\"{name}: {conf*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63a29af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: saved_models/resnet50_compcars_20260111_154612.pth\n",
      "Class mapping saved to: saved_models/class_to_idx_20260111_154612.json\n",
      "Metadata saved to: saved_models/training_meta_20260111_154612.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a folder for saved models\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 1. Save model weights\n",
    "model_path = f\"saved_models/resnet50_compcars_{timestamp}.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# 2. Save class mapping\n",
    "class_map_path = f\"saved_models/class_to_idx_{timestamp}.json\"\n",
    "with open(class_map_path, \"w\") as f:\n",
    "    json.dump(train_dataset.class_to_idx, f, indent=2)\n",
    "\n",
    "# 3. Save training metadata\n",
    "meta = {\n",
    "    \"architecture\": \"resnet50\",\n",
    "    \"num_classes\": 429,\n",
    "    \"backbone\": \"ImageNet pretrained\",\n",
    "    \"phase2_unfrozen\": \"layer4\",\n",
    "    \"top1_test\": 0.60,\n",
    "    \"top5_test\": 0.8001,\n",
    "    \"dataset\": \"CompCars\",\n",
    "    \"split\": \"80/20 train/val per class, official test\",\n",
    "}\n",
    "\n",
    "meta_path = f\"saved_models/training_meta_{timestamp}.json\"\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Model saved to:\", model_path)\n",
    "print(\"Class mapping saved to:\", class_map_path)\n",
    "print(\"Metadata saved to:\", meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff83965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'types'])\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"D:\\CompCars\\misc\\car_type.mat\")\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254c5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'make_names', 'model_names'])\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"D:\\CompCars\\misc\\make_model_name.mat\")\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9bfea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
